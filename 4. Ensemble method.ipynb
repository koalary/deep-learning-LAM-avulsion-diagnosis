{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df08933",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Flatten, Dense, Lambda\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.applications import Xception # TensorFlow ONLY\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "def load_image(img_url):\n",
    "    image = load_img(img_url,target_size=(512,512))\n",
    "    image = img_to_array(image)\n",
    "    image /= 255\n",
    "    image = np.expand_dims(image,axis=0)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297fdf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_path = './testing set/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af1d3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = []\n",
    "import os\n",
    "def get_data(Dir):\n",
    "    X = []\n",
    "    y = []\n",
    "    for nextDir in os.listdir(Dir):\n",
    "        if not nextDir.startswith('.'):\n",
    "            if nextDir in ['Normal']:\n",
    "                label = 0\n",
    "            elif nextDir in ['LAMA']:\n",
    "                label = 1\n",
    "                \n",
    "            temp = Dir + nextDir\n",
    "                \n",
    "            for file in tqdm(os.listdir(temp)):\n",
    "                image = load_img(temp + '/' + file,target_size=(512,512))\n",
    "                image = img_to_array(image)\n",
    "                image /= 255\n",
    "                X.append(image)\n",
    "                y.append(label)\n",
    "                image_list.append(file)   \n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d2ee7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test,y_test = get_data(test_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129bc46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "Y_test = to_categorical(y_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9407a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model, load_model\n",
    "model_a = load_model('IV3_2.h5')\n",
    "model_b = load_model('res2.h5')\n",
    "model_c = load_model('Xception_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd5b503",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='LAIM', cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.rcParams['savefig.dpi'] = 500\n",
    "    plt.rcParams['figure.dpi'] = 500\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438a4517",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ya_pred = model_a.predict(x_test)\n",
    "Yb_pred = model_b.predict(x_test)\n",
    "Yc_pred = model_c.predict(x_test)\n",
    "Yensemble_pred = (Ya_pred+Yb_pred+Yc_pred)/3.0\n",
    "\n",
    "\n",
    "# Convert predictions classes from one hot vectors to labels: [0 0 1 0 0 ...] --> 2\n",
    "y_pred = np.argmax(Yensemble_pred, axis=1)\n",
    "# Convert validation observations from one hot vectors to labels\n",
    "#y_true = np.argmax(Y_valid, axis=1)\n",
    "y_true = y_test\n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(y_true, y_pred)\n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_mtx, classes=['Normal','LAMA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9354e4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_mat_norm = confusion_mtx.astype('float') / confusion_mtx.sum(axis=1)[:, np.newaxis]     # proportion\n",
    "con_mat_norm = np.around(con_mat_norm, decimals=2)\n",
    "\n",
    "plot_confusion_matrix(confusion_mtx, classes=['Normal','LAMA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1684579e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print('Classification Report')\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "    \n",
    "from sklearn.metrics import roc_curve, auc\n",
    "# Compute ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(Y_test.ravel(), Yensemble_pred.ravel())\n",
    "\n",
    "# Compute ROC area\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('ROC area is {0}'.format(roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9698e4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='red', linestyle='-.',label='test (AUC = %0.3f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', linestyle=':')\n",
    "plt.xlim([-0.01, 1.0])\n",
    "plt.ylim([0.0, 1.01])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC on External Dataset')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6502727b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac88b71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b363b3b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b65671c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b02163",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
